{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ3WKIBK5PA5",
        "outputId": "9b6bbca5-eb17-47a5-8bb2-bd7c02d23abf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun  6 14:34:30 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    28W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q langchain transformers sentence_transformers llama-index\n"
      ],
      "metadata": {
        "id": "5i9un3Xh5QlE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import SimpleDirectoryReader, LangchainEmbedding, GPTListIndex,GPTVectorStoreIndex, PromptHelper\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index import LLMPredictor, ServiceContext\n",
        "import torch\n",
        "from langchain.llms.base import LLM\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "Li_RlLpu5RD3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class customLLM(LLM):\n",
        "    model_name = \"google/flan-t5-large\"\n",
        "    pipeline = pipeline(\"text2text-generation\", model=model_name, device=0, model_kwargs={\"torch_dtype\":torch.bfloat16})\n",
        "\n",
        "    def _call(self, prompt, stop=None):\n",
        "        return self.pipeline(prompt, max_length=9999)[0][\"generated_text\"]\n",
        "    @property\n",
        "    def _identifying_params(self):\n",
        "        return {\"name_of_model\": self.model_name}\n",
        "    @property\n",
        "    def _llm_type(self):\n",
        "        return \"custom\"\n",
        "\n",
        "\n",
        "llm_predictor = LLMPredictor(llm=customLLM())\n"
      ],
      "metadata": {
        "id": "s4AvZVTe5THM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hfemb = HuggingFaceEmbeddings()\n",
        "embed_model = LangchainEmbedding(hfemb)\n"
      ],
      "metadata": {
        "id": "fgX6vvpq5UxH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"\"\" McDonald's: A Global Icon of Fast Food\n",
        "\n",
        "McDonald's, the world's largest fast-food chain, has become an iconic symbol of the global food industry. With its golden arches, cheerful red and yellow logo, and distinctive menu items, McDonald's has permeated almost every corner of the world, serving billions of customers since its inception.\n",
        "\n",
        "The story of McDonald's began in 1940 when Richard and Maurice McDonald opened a small burger stand in San Bernardino, California. Initially, their restaurant focused on offering a limited menu with a strong emphasis on speed and efficiency. However, it was not until 1955 when Ray Kroc, a visionary entrepreneur, joined forces with the brothers and transformed McDonald's into a franchise business.\n",
        "\n",
        "Kroc's genius lay in recognizing the potential for standardization and mass production in the fast-food industry. He implemented a system that allowed every McDonald's location to serve the same menu items, maintaining consistency in taste and quality. This system, coupled with an aggressive marketing strategy, propelled McDonald's to unprecedented heights of success.\n",
        "\n",
        "The McDonald's menu, known for its iconic items such as the Big Mac, Quarter Pounder, and Chicken McNuggets, has evolved over the years to cater to changing consumer preferences. In recent times, the company has also made efforts to introduce healthier options, such as salads and grilled chicken sandwiches, to accommodate a more health-conscious customer base.\n",
        "\n",
        "One of the key factors contributing to McDonald's global dominance is its commitment to localization. While the core menu remains consistent worldwide, McDonald's adapts its offerings to suit local tastes and cultural preferences. For example, in India, where a significant portion of the population follows vegetarian diets, McDonald's introduced a range of vegetarian options like the McAloo Tikki and the Maharaja Mac.\n",
        "\n",
        "Beyond its culinary offerings, McDonald's has also made a significant impact on popular culture. The brand's iconic advertising campaigns, featuring memorable characters like Ronald McDonald and catchy slogans like \"I'm lovin' it,\" have permeated television screens and billboards worldwide. McDonald's has also established itself as a community gathering place, hosting birthday parties, sponsoring sports events, and supporting charitable initiatives.\n",
        "\n",
        "However, McDonald's has not been without its share of controversies. The company has faced criticism for its contribution to the rise in obesity rates, its environmental footprint, and its labor practices. In response, McDonald's has taken steps to address these concerns. They have introduced healthier menu options, made commitments to sustainable sourcing, and increased employee wages in some regions.\n",
        "\n",
        "Looking ahead, McDonald's continues to innovate and adapt to changing consumer demands. The company has embraced technology by introducing self-ordering kiosks, mobile ordering, and delivery services. Additionally, McDonald's has made significant strides in reducing its environmental impact by setting goals to minimize packaging waste and increase recycling.\n",
        "\n",
        "In conclusion, McDonald's has emerged as a global icon of fast food, captivating billions of customers worldwide. Its commitment to consistency, localization, and customer satisfaction has made it a dominant force in the industry. While it faces challenges and controversies, McDonald's remains an influential player shaping the fast-food landscape and continuing to evolve to meet the needs of its diverse consumer base.\"\"\""
      ],
      "metadata": {
        "id": "UCbf-O3X5Wb1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install PyPDF2"
      ],
      "metadata": {
        "id": "S6dl39GcIM_C"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # importing required modules\n",
        "# from PyPDF2 import PdfReader\n",
        "  \n",
        "# # creating a pdf reader object\n",
        "# reader = PdfReader('sbc-sample.pdf')\n",
        "  \n",
        "# # Initialize an empty string to store the combined text\n",
        "# combined_text = \"\"\n",
        "\n",
        "# # Iterate over all pages\n",
        "# for page in reader.pages:\n",
        "#     # Extracting text from each page\n",
        "#     text = page.extract_text()\n",
        "#     # Append the text to the combined_text string\n",
        "#     combined_text += text\n",
        "\n",
        "# # Print the combined text\n",
        "# print(combined_text)"
      ],
      "metadata": {
        "id": "xO74RtS0HdiF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#documents = SimpleDirectoryReader('data').load_data()\n",
        "\n",
        "from llama_index import Document\n",
        "\n",
        "text_list = [text1]\n",
        "\n",
        "documents = [Document(t) for t in text_list]"
      ],
      "metadata": {
        "id": "hwyjsc9U5u_w"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # set number of output tokens\n",
        "# num_output = 500\n",
        "# # set maximum input size\n",
        "# max_input_size = 512\n",
        "# # set maximum chunk overlap\n",
        "# max_chunk_overlap = 15\n",
        "\n",
        "\n",
        "# prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)\n",
        "     "
      ],
      "metadata": {
        "id": "y_2Dl63v5wzb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#index = GPTSimpleVectorIndex(documents, embed_model=embed_model, llm_predictor=llm_predictor)\n",
        "\n",
        "#index = GPTListIndex.from_documents(documents, embed_model=embed_model, llm_predictor=llm_predictor)\n",
        "\n",
        "#index.save_to_disk('index.json')\n",
        "\n",
        "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, embed_model=embed_model)\n",
        "index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)\n"
      ],
      "metadata": {
        "id": "woxcMHEY5zFg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.getLogger().setLevel(logging.CRITICAL)"
      ],
      "metadata": {
        "id": "7eFwhquj51WM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#response = index.query( \"What's the cost of Whisper model?\") \n"
      ],
      "metadata": {
        "id": "VwWo9L3I51xQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()\n",
        "prompt = \"who was the founder McDonalds\"\n",
        "response = query_engine.query(prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsXlelH6AmJS",
        "outputId": "85aa5d0a-5f88-405f-f83d-c982d54b5fc1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "McDonalds was founded by James McDonald\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SABpcXqbFVGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SrLpHOirFVI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HnIlSsXEFVLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8YnUcD-dFVNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KdmnScjdFVPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FMvQtkUFFVRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hi5ea3FSFVSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9vVMshpDFVUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d6D-AK-wFVWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZNRHxZ6jFVYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fjCc_S6QFVZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uZOUJiEbFVbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PxH4NkY6FVdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a5pMoFUYFVfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w0g8W8BFFVhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JLxl7kh3FVjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9WIzgy5aFVll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46pcrMiGC0Vv",
        "outputId": "adbb0a24-6eac-4aa3-f28b-e683b04ef941"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-H\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    service_context=service_context,\n",
        "    similarity_top_k=2,\n",
        "    # response_mode=\"tree_summarize\"\n",
        ")\n",
        "response = query_engine.query(\n",
        "    \"What did the author do growing up?\",\n",
        ")"
      ],
      "metadata": {
        "id": "OK5mMmnQC0Xg"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "emtgNFfeC0Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7lON8_xgC0aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JBXBGPFIC0ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W8mL_HLrC0eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LGr9ATWDC0f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQt6xurpC0he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.response\n"
      ],
      "metadata": {
        "id": "xNiYgBhG51zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temp fix for running shell commands on Google Colab\n",
        "\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "NZeYv6aR5137"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio -q\n"
      ],
      "metadata": {
        "id": "ZHInNR-w515k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n"
      ],
      "metadata": {
        "id": "VxQ5lrQg57sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = None\n"
      ],
      "metadata": {
        "id": "kPemiVYF57uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_the_bot(input_text):\n",
        "  text_list = [input_text]\n",
        "  documents = [Document(t) for t in text_list]\n",
        "  global index\n",
        "  service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, embed_model=embed_model)\n",
        "  index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)\n",
        "  return('Index saved successfull!!!')"
      ],
      "metadata": {
        "id": "351k669w57v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(chat_history, user_input):\n",
        "  \n",
        "  bot_response = index.query(user_input)\n",
        "  #print(bot_response)\n",
        "  response = \"\"\n",
        "  for letter in ''.join(bot_response.response): #[bot_response[i:i+1] for i in range(0, len(bot_response), 1)]:\n",
        "      response += letter + \"\"\n",
        "      yield chat_history + [(user_input, response)]"
      ],
      "metadata": {
        "id": "VdTotTm057xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown('# Q&A Bot with Hugging Face Models')\n",
        "    with gr.Tab(\"Input Text Document\"):\n",
        "        text_input = gr.Textbox()\n",
        "        text_output = gr.Textbox()\n",
        "        text_button = gr.Button(\"Build the Bot!!!\")\n",
        "        text_button.click(build_the_bot, text_input, text_output)\n",
        "    with gr.Tab(\"Knowledge Bot\"):\n",
        "#          inputbox = gr.Textbox(\"Input your text to build a Q&A Bot here.....\")\n",
        "          chatbot = gr.Chatbot()\n",
        "          message = gr.Textbox (\"What is this document about?\")\n",
        "          message.submit(chat, [chatbot, message], chatbot)\n",
        "\n",
        "demo.queue().launch(debug = True)\n"
      ],
      "metadata": {
        "id": "SC34uDGz57zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eOoRc13r571O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUOld2rb5724"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B2cEhtz05740"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZR1yWsGH577C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EsReQVcX578T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7JKMih6Q57-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQzN5XWA57_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E6gLYxbm517d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}